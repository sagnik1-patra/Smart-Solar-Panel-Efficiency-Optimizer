{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56131ca-d262-4f56-89c4-78bb30dd66ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset shape: (136472, 13)\n",
      "[INFO] Columns available: ['DATE_TIME', 'PLANT_ID_x', 'SOURCE_KEY_x', 'DC_POWER', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD', 'PLANT_ID_y', 'SOURCE_KEY_y', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION', 'PLANT_ID']\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_17540\\3400576068.py:42: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  weather = pd.read_csv(weather_path, parse_dates=['DATE_TIME'], dayfirst=True)\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_17540\\3400576068.py:41: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  gen = pd.read_csv(gen_path, parse_dates=['DATE_TIME'], dayfirst=True)\n",
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_17540\\3400576068.py:42: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  weather = pd.read_csv(weather_path, parse_dates=['DATE_TIME'], dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "[OPT] Iter 01 | RMSE=0.3944 | hidden=69, lr=0.00794, drop=0.33\n",
      "[OPT] Iter 02 | RMSE=0.4221 | hidden=88, lr=0.00417, drop=0.28\n",
      "[OPT] Iter 03 | RMSE=0.3800 | hidden=65, lr=0.00729, drop=0.25\n",
      "[OPT] Iter 04 | RMSE=0.4850 | hidden=33, lr=0.00279, drop=0.21\n",
      "[OPT] Iter 05 | RMSE=0.4391 | hidden=103, lr=0.00812, drop=0.36\n",
      "[INFO] Best Parameters: {'hidden': 65, 'lr': 0.007291037550166211, 'dropout': 0.24946410997597523}\n",
      "Epoch 1/40\n",
      "1365/1365 [==============================] - 5s 2ms/step - loss: 0.0332 - val_loss: 0.2160\n",
      "Epoch 2/40\n",
      "1365/1365 [==============================] - 3s 2ms/step - loss: 0.0251 - val_loss: 0.2431\n",
      "Epoch 3/40\n",
      "1365/1365 [==============================] - 3s 2ms/step - loss: 0.0215 - val_loss: 0.2809\n",
      "Epoch 4/40\n",
      "1365/1365 [==============================] - 3s 2ms/step - loss: 0.0206 - val_loss: 0.3016\n",
      "Epoch 5/40\n",
      "1365/1365 [==============================] - 3s 2ms/step - loss: 0.0193 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1365/1365 [==============================] - 3s 2ms/step - loss: 0.0188 - val_loss: 0.2868\n",
      "853/853 [==============================] - 1s 1ms/step\n",
      "[RESULT] RMSE: 0.6028, R2: -0.5242\n",
      "[INFO] ‚úÖ All models & configs saved in: C:\\Users\\NXTWAVE\\Downloads\\Smart Solar Panel Efficiency Optimizer\\results\n",
      "[INFO] Files generated: ['scaler_x.pkl', 'scaler_y.pkl', 'SolarSense_config.yaml', 'SolarSense_model.h5', 'SolarSense_results.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üåû SolarSense | Smart Solar Panel Efficiency Optimizer (Fixed)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ CONFIGURATION\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Smart Solar Panel Efficiency Optimizer\\archive\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Smart Solar Panel Efficiency Optimizer\\results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "files = {\n",
    "    \"plant1_gen\": os.path.join(DATA_DIR, \"Plant_1_Generation_Data.csv\"),\n",
    "    \"plant1_weather\": os.path.join(DATA_DIR, \"Plant_1_Weather_Sensor_Data.csv\"),\n",
    "    \"plant2_gen\": os.path.join(DATA_DIR, \"Plant_2_Generation_Data.csv\"),\n",
    "    \"plant2_weather\": os.path.join(DATA_DIR, \"Plant_2_Weather_Sensor_Data.csv\"),\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ LOAD DATASETS\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def load_and_merge(gen_path, weather_path):\n",
    "    gen = pd.read_csv(gen_path, parse_dates=['DATE_TIME'], dayfirst=True)\n",
    "    weather = pd.read_csv(weather_path, parse_dates=['DATE_TIME'], dayfirst=True)\n",
    "\n",
    "    # Merge on DATE_TIME\n",
    "    df = pd.merge(gen, weather, on=\"DATE_TIME\", how=\"inner\")\n",
    "\n",
    "    # Identify plant ID if missing\n",
    "    if 'PLANT_ID_x' in df.columns:\n",
    "        df['PLANT_ID'] = df['PLANT_ID_x']\n",
    "    elif 'PLANT_ID' not in df.columns:\n",
    "        df['PLANT_ID'] = os.path.basename(gen_path).split('_')[1]\n",
    "\n",
    "    return df\n",
    "\n",
    "df1 = load_and_merge(files[\"plant1_gen\"], files[\"plant1_weather\"])\n",
    "df2 = load_and_merge(files[\"plant2_gen\"], files[\"plant2_weather\"])\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(\"[INFO] Dataset shape:\", df.shape)\n",
    "print(\"[INFO] Columns available:\", list(df.columns)[:15])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ FEATURE ENGINEERING\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ensure key columns exist\n",
    "for col in ['DC_POWER', 'AC_POWER', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']:\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Missing expected column: {col}\")\n",
    "\n",
    "# Compute efficiency safely\n",
    "df[\"EFFICIENCY\"] = np.where(df[\"DC_POWER\"] > 0, df[\"AC_POWER\"] / df[\"DC_POWER\"], 0)\n",
    "\n",
    "# Extract time-based features\n",
    "df[\"HOUR\"] = df[\"DATE_TIME\"].dt.hour\n",
    "df[\"DAY\"] = df[\"DATE_TIME\"].dt.day\n",
    "df[\"MONTH\"] = df[\"DATE_TIME\"].dt.month\n",
    "\n",
    "# Select feature and target columns\n",
    "feature_cols = [\"AMBIENT_TEMPERATURE\", \"MODULE_TEMPERATURE\", \"IRRADIATION\", \"HOUR\", \"DAY\", \"MONTH\"]\n",
    "target_col = \"EFFICIENCY\"\n",
    "\n",
    "df = df.dropna(subset=feature_cols + [target_col])\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ SCALE FEATURES\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ TRAIN / TEST SPLIT\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape for LSTM (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ PSO-Like RANDOM SEARCH (light version)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def random_search_optimize(n_iter=5):\n",
    "    best_rmse = np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        lr = random.uniform(0.0005, 0.01)\n",
    "        hidden = random.randint(32, 128)\n",
    "        dropout = random.uniform(0.1, 0.4)\n",
    "\n",
    "        model = Sequential([\n",
    "            Conv1D(32, kernel_size=1, activation='relu', input_shape=(1, X_train.shape[2])),\n",
    "            Flatten(),\n",
    "            Dense(hidden, activation='relu'),\n",
    "            Dropout(dropout),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mse')\n",
    "        model.fit(X_train, y_train, epochs=3, batch_size=64, verbose=0)\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        print(f\"[OPT] Iter {i+1:02d} | RMSE={rmse:.4f} | hidden={hidden}, lr={lr:.5f}, drop={dropout:.2f}\")\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = {\"hidden\": hidden, \"lr\": lr, \"dropout\": dropout}\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "best_params = random_search_optimize()\n",
    "print(\"[INFO] Best Parameters:\", best_params)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7Ô∏è‚É£ BUILD FINAL HYBRID MODEL (CNN + LSTM)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=1, activation='relu', input_shape=(1, X_train.shape[2])),\n",
    "    LSTM(best_params[\"hidden\"], return_sequences=False),\n",
    "    Dropout(best_params[\"dropout\"]),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[\"lr\"]), loss='mse')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=40, batch_size=64, callbacks=[es], verbose=1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8Ô∏è‚É£ EVALUATION\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "print(f\"[RESULT] RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9Ô∏è‚É£ SAVE ALL OUTPUTS (.h5, .pkl, .yaml, .json)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Model\n",
    "model.save(os.path.join(OUTPUT_DIR, \"SolarSense_model.h5\"))\n",
    "\n",
    "# Scalers\n",
    "with open(os.path.join(OUTPUT_DIR, \"scaler_x.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler_x, f)\n",
    "with open(os.path.join(OUTPUT_DIR, \"scaler_y.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "\n",
    "# Config (YAML)\n",
    "config = {\n",
    "    \"features\": feature_cols,\n",
    "    \"target\": target_col,\n",
    "    \"best_params\": best_params,\n",
    "    \"metrics\": {\"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"SolarSense_config.yaml\"), \"w\") as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "# Results (JSON)\n",
    "summary_report = {\n",
    "    \"Dataset Shape\": df.shape,\n",
    "    \"RMSE\": rmse,\n",
    "    \"R2\": r2,\n",
    "    \"Best Hyperparameters\": best_params,\n",
    "    \"Output Files\": os.listdir(OUTPUT_DIR)\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"SolarSense_results.json\"), \"w\") as f:\n",
    "    json.dump(summary_report, f, indent=4)\n",
    "\n",
    "print(\"[INFO] ‚úÖ All models & configs saved in:\", OUTPUT_DIR)\n",
    "print(\"[INFO] Files generated:\", os.listdir(OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cb09f-c54d-4d63-9ef7-4d27e6e0f40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
